#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ—¥æœ¬é‚®æ”¿è¿½è¸ªä¿¡æ¯çˆ¬è™«
ç”¨äºçˆ¬å–æ—¥æœ¬é‚®æ”¿å®˜ç½‘çš„åŒ…è£¹è¿½è¸ªä¿¡æ¯
"""

import requests
from bs4 import BeautifulSoup
import json
import re
import os
from typing import Dict, List, Optional
import pymysql
from datetime import datetime


class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†ç±»"""
    
    def __init__(self, host='localhost', port=3306, user='root', password='', database='seas_ware', charset='utf8mb4'):
        """
        åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        
        Args:
            host: æ•°æ®åº“ä¸»æœºåœ°å€
            port: æ•°æ®åº“ç«¯å£
            user: æ•°æ®åº“ç”¨æˆ·å
            password: æ•°æ®åº“å¯†ç 
            database: æ•°æ®åº“åç§°
            charset: å­—ç¬¦é›†
        """
        self.host = host
        self.port = port
        self.user = user
        self.password = password
        self.database = database
        self.charset = charset
        self.connection = None
    
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.connection = pymysql.connect(
                host=self.host,
                port=self.port,
                user=self.user,
                password=self.password,
                database=self.database,
                charset=self.charset,
                cursorclass=pymysql.cursors.DictCursor
            )
            print(f"æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“: {self.database}")
            return True
        except Exception as e:
            print(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
            return False
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.connection:
            self.connection.close()
            print("æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def create_tables(self):
        """åˆ›å»ºæ•°æ®è¡¨"""
        if not self.connection:
            print("æ•°æ®åº“æœªè¿æ¥")
            return False
        
        try:
            with self.connection.cursor() as cursor:
                # åˆ›å»ºå†å²è®°å½•è¡¨
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS tracking_history (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        item_number VARCHAR(50) NOT NULL COMMENT 'ç‰©å“ç¼–å·',
                        date VARCHAR(50) COMMENT 'æ—¥æœŸ',
                        shipping_track_record VARCHAR(200) COMMENT 'é…é€è®°å½•',
                        details TEXT COMMENT 'è¯¦æƒ…',
                        office VARCHAR(100) COMMENT 'åŠå…¬å®¤',
                        zip_code VARCHAR(20) COMMENT 'é‚®ç¼–',
                        prefecture VARCHAR(50) COMMENT 'éƒ½é“åºœå¿',
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
                        INDEX idx_item_number (item_number),
                        INDEX idx_date (date)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='è¿½è¸ªå†å²è®°å½•è¡¨'
                """)
            
            self.connection.commit()
            print("æ•°æ®è¡¨åˆ›å»ºæˆåŠŸ")
            return True
        except Exception as e:
            print(f"åˆ›å»ºæ•°æ®è¡¨å¤±è´¥: {str(e)}")
            self.connection.rollback()
            return False
    
    def save_tracking_data(self, tracking_number: str, data: Dict) -> bool:
        """
        ä¿å­˜è¿½è¸ªæ•°æ®åˆ°æ•°æ®åº“ï¼ˆåªä¿å­˜ historyï¼‰
        
        Args:
            tracking_number: è¿½è¸ªå·
            data: è¿½è¸ªæ•°æ®å­—å…¸
        
        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        if not self.connection:
            print("æ•°æ®åº“æœªè¿æ¥")
            return False
        
        try:
            with self.connection.cursor() as cursor:
                # åªä¿å­˜å†å²è®°å½•ï¼Œä½¿ç”¨ tracking_number ä½œä¸º item_number
                if data.get('history'):
                    for history in data['history']:
                        cursor.execute("""
                            INSERT INTO tracking_history 
                            (item_number, date, shipping_track_record, details, office, zip_code, prefecture)
                            VALUES (%s, %s, %s, %s, %s, %s, %s)
                        """, (
                            tracking_number,  # ä½¿ç”¨ tracking_number ä½œä¸º item_number
                            history.get('date', ''),
                            history.get('shipping_track_record', ''),
                            history.get('details', ''),
                            history.get('office', ''),
                            history.get('zip_code', ''),
                            history.get('prefecture', '')
                        ))
                
                self.connection.commit()
                print(f"å†å²è®°å½•å·²ä¿å­˜åˆ°æ•°æ®åº“: {tracking_number}")
                return True
        except Exception as e:
            print(f"ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {str(e)}")
            self.connection.rollback()
            return False

    def fetch_pending_search_numbers(self) -> List[Dict]:
        """
        è·å–éœ€è¦æŸ¥è¯¢çš„è¿½è¸ªå·ï¼ˆè¿‡æ»¤å·²å®ŒæˆçŠ¶æ€ï¼‰
        Returns:
            [{'search_num': '...', 'states': '...'}, ...]
        """
        if not self.connection:
            print("æ•°æ®åº“æœªè¿æ¥")
            return []
        try:
            with self.connection.cursor() as cursor:
                cursor.execute("""
                    SELECT search_num, states
                    FROM Post_searchs
                    WHERE states NOT IN ('Final delivery', 'Returned to sender')
                       OR states IS NULL
                """)
                rows = cursor.fetchall()
                return rows
        except Exception as e:
            print(f"è·å–å¾…æŸ¥è¯¢è¿½è¸ªå·å¤±è´¥: {str(e)}")
            return []

    def update_search_state(self, search_num: str, new_state: str) -> bool:
        """æ›´æ–° Post_searchs è¡¨çš„çŠ¶æ€"""
        if not self.connection:
            print("æ•°æ®åº“æœªè¿æ¥")
            return False
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(
                    "UPDATE Post_searchs SET states = %s WHERE search_num = %s",
                    (new_state, search_num)
                )
            self.connection.commit()
            print(f"å·²æ›´æ–° {search_num} çŠ¶æ€ä¸º {new_state}")
            return True
        except Exception as e:
            print(f"æ›´æ–°çŠ¶æ€å¤±è´¥: {str(e)}")
            self.connection.rollback()
            return False


class JapanPostCrawler:
    """æ—¥æœ¬é‚®æ”¿è¿½è¸ªä¿¡æ¯çˆ¬è™«ç±»"""
    
    def __init__(self, db_config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–çˆ¬è™«
        
        Args:
            db_config: æ•°æ®åº“é…ç½®å­—å…¸ï¼Œå¦‚æœæä¾›åˆ™è‡ªåŠ¨è¿æ¥æ•°æ®åº“
        """
        self.base_url = "https://trackings.post.japanpost.jp/services/srv/search/direct"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        self.db_manager = None
        if db_config:
            self.db_manager = DatabaseManager(**db_config)
            if self.db_manager.connect():
                self.db_manager.create_tables()
    
    def fetch_tracking_info(self, tracking_number: str, return_html: bool = False) -> Optional[Dict]:
        """
        è·å–è¿½è¸ªä¿¡æ¯
        
        Args:
            tracking_number: è¿½è¸ªå·ï¼ˆå¦‚ï¼š628327933074ï¼‰
            return_html: æ˜¯å¦åœ¨è¿”å›ç»“æœä¸­åŒ…å«åŸå§‹HTML
        
        Returns:
            åŒ…å«è¿½è¸ªä¿¡æ¯çš„å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        # æ„å»ºè¯·æ±‚URL
        params = {
            'searchKind': 'S004',
            'locale': 'en',
            'reqCodeNo1': tracking_number,
            'x': '29',
            'y': '9'
        }
        
        try:
            # å‘é€GETè¯·æ±‚
            response = requests.get(
                self.base_url,
                params=params,
                headers=self.headers,
                timeout=30
            )
            response.encoding = 'utf-8'
            
            if response.status_code == 200:
                result = self.parse_html(response.text)
                if return_html and result:
                    result['raw_html'] = response.text
                return result
            else:
                print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")
            return None
    
    def fetch_raw_html(self, tracking_number: str) -> Optional[str]:
        """
        è·å–åŸå§‹HTMLå†…å®¹
        
        Args:
            tracking_number: è¿½è¸ªå·ï¼ˆå¦‚ï¼š628327933074ï¼‰
        
        Returns:
            åŸå§‹HTMLå­—ç¬¦ä¸²ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        params = {
            'searchKind': 'S004',
            'locale': 'en',
            'reqCodeNo1': tracking_number,
            'x': '29',
            'y': '9'
        }
        
        try:
            response = requests.get(
                self.base_url,
                params=params,
                headers=self.headers,
                timeout=30
            )
            response.encoding = 'utf-8'
            
            if response.status_code == 200:
                return response.text
            else:
                print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")
            return None
    
    def parse_html(self, html_content: str) -> Dict:
        """
        è§£æHTMLå†…å®¹ï¼Œæå–è¿½è¸ªä¿¡æ¯
        
        Args:
            html_content: HTMLå†…å®¹
        
        Returns:
            åŒ…å«è§£æåæ•°æ®çš„å­—å…¸
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        
        result = {
            'history': []
        }
        
        # æå–å†å²ä¿¡æ¯
        history_table = soup.find('table', {'summary': 'å±¥æ­´æƒ…å ±'})
        if history_table:
            rows = history_table.find_all('tr')
            i = 2  # è·³è¿‡è¡¨å¤´è¡Œ
            while i < len(rows):
                row = rows[i]
                cells = row.find_all(['td', 'th'])
                
                if len(cells) >= 5:
                    # æ£€æŸ¥æ˜¯å¦æœ‰rowspan
                    date_cell = cells[0]
                    date = date_cell.get_text(strip=True)
                    
                    # è·å–rowspanå€¼
                    rowspan = int(date_cell.get('rowspan', 1))
                    
                    if rowspan == 2:
                        # ç¬¬ä¸€è¡Œæ•°æ®
                        track_record = cells[1].get_text(strip=True)
                        details = cells[2].get_text(strip=True)
                        office = cells[3].get_text(strip=True)
                        prefecture = cells[4].get_text(strip=True)
                        
                        # ä¸‹ä¸€è¡Œæ˜¯é‚®ç¼–
                        if i + 1 < len(rows):
                            next_row = rows[i + 1]
                            zip_cells = next_row.find_all('td')
                            zip_code = zip_cells[0].get_text(strip=True) if zip_cells else ""
                        else:
                            zip_code = ""
                        
                        result['history'].append({
                            'date': date,
                            'shipping_track_record': track_record,
                            'details': details,
                            'office': office,
                            'zip_code': zip_code,
                            'prefecture': prefecture
                        })
                        
                        i += 2  # è·³è¿‡ä¸¤è¡Œ
                    else:
                        i += 1
        
        return result
    
    def save_to_file(self, data: Dict, filepath: str, format: str = 'json'):
        """
        ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶
        
        Args:
            data: è¦ä¿å­˜çš„æ•°æ®
            filepath: æ–‡ä»¶è·¯å¾„
            format: ä¿å­˜æ ¼å¼ ('json' æˆ– 'html')
        """
        try:
            if format == 'json':
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
            elif format == 'html':
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(data)
            print(f"æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        except Exception as e:
            print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def save_raw_html(self, html_content: str, filepath: str):
        """
        ä¿å­˜åŸå§‹HTMLå†…å®¹
        
        Args:
            html_content: HTMLå†…å®¹
            filepath: æ–‡ä»¶è·¯å¾„
        """
        self.save_to_file(html_content, filepath, format='html')
    
    def save_to_database(self, tracking_number: str, data: Dict) -> bool:
        """
        ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
        
        Args:
            tracking_number: è¿½è¸ªå·
            data: è¿½è¸ªæ•°æ®å­—å…¸
        
        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        if not self.db_manager:
            print("æ•°æ®åº“æœªé…ç½®")
            return False
        
        return self.db_manager.save_tracking_data(tracking_number, data)
    
    def close_database(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.db_manager:
            self.db_manager.close()


def load_db_config(config_file: str = 'db_config.json') -> Optional[Dict]:
    """
    ä»é…ç½®æ–‡ä»¶åŠ è½½æ•°æ®åº“é…ç½®
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        æ•°æ®åº“é…ç½®å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                print(f"å·²ä»é…ç½®æ–‡ä»¶åŠ è½½æ•°æ®åº“é…ç½®: {config_file}")
                return config
        else:
            print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return None
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None


def main():
    """ä¸»å‡½æ•°"""
    # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½æ•°æ®åº“é…ç½®
    db_config = load_db_config('db_config.json')
    
    # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    if not db_config:
        db_config = {
            'host': 'localhost',
            'port': 3306,
            'user': 'root',
            'password': '',  # è¯·å¡«å†™æ•°æ®åº“å¯†ç 
            'database': 'seas_ware',
            'charset': 'utf8mb4'
        }
        print("ä½¿ç”¨é»˜è®¤æ•°æ®åº“é…ç½®")
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹ï¼ˆè‡ªåŠ¨è¿æ¥æ•°æ®åº“ï¼‰
    crawler = JapanPostCrawler(db_config=db_config)
    
    # å¦‚æœé…ç½®äº†æ•°æ®åº“ï¼Œåˆ™ä» Post_searchs è¡¨è¯»å–å¾…æŸ¥è¯¢è¿½è¸ªå·
    tracking_numbers = []
    if crawler.db_manager:
        tracking_numbers = crawler.db_manager.fetch_pending_search_numbers()
    
    # å¦‚æœæ•°æ®åº“æ²¡æœ‰è®°å½•ï¼Œé€€å›åˆ°å•ä¸ªç¤ºä¾‹è¿½è¸ªå·
    if not tracking_numbers:
        tracking_numbers = [{'search_num': "628327933074", 'states': None}]
        print("æœªåœ¨æ•°æ®åº“ä¸­æ‰¾åˆ°å¾…æŸ¥è¯¢è¿½è¸ªå·ï¼Œä½¿ç”¨é»˜è®¤ç¤ºä¾‹ã€‚")
    
    # è¿”å›å€¼æ–‡ä»¶è·¯å¾„ï¼ˆå…±ç”¨ï¼‰
    return_filepath = r"C:\Users\Administrator\Desktop\æµ·å¤–ä»“\è¿”å›å€¼"

    # ç”¨äºæ”¶é›†æŸ¥è¯¢å¤±è´¥çš„å•å·
    failed_tracking_numbers = []

    print(f"ğŸ“‹ å¼€å§‹å¤„ç† {len(tracking_numbers)} ä¸ªè¿½è¸ªå·...")
    print("=" * 60)

    for item in tracking_numbers:
        tracking_number = str(item.get('search_num') or item)
        states = item.get('states')
        
        # è·³è¿‡å·²å®Œæˆçš„å•å·
        if states in ('Final delivery', 'Returned to sender'):
            print(f"è·³è¿‡å·²å®Œæˆ: {tracking_number} (çŠ¶æ€: {states})")
            continue
        
        print(f"\næ­£åœ¨æŸ¥è¯¢è¿½è¸ªå·: {tracking_number}")
        print("-" * 50)
        
        # è·å–åŸå§‹HTMLå¹¶ä¿å­˜åˆ°è¿”å›å€¼æ–‡ä»¶
        raw_html = crawler.fetch_raw_html(tracking_number)
        if raw_html:
            crawler.save_raw_html(raw_html, return_filepath)
            print(f"åŸå§‹HTMLå·²ä¿å­˜åˆ°: {return_filepath}")

            # æ£€æŸ¥æ˜¯å¦ä¸ºæœªæ³¨å†Œçš„å•å·
            if 'Your item was not found' in raw_html:
                print("âŒ å‘ç°é”™è¯¯ï¼šå•å·æœªæ‰¾åˆ°")
                if crawler.db_manager:
                    crawler.db_manager.update_search_state(tracking_number, 'Not registered')
                print("\n" + "=" * 50)
                print("æŸ¥è¯¢å®Œæˆï¼")
                continue

        # è·å–å¹¶è§£æè¿½è¸ªä¿¡æ¯
        result = crawler.fetch_tracking_info(tracking_number)
        
        if result:
            # æ‰“å°ç»“æœ
            print("\n=== å†å²ä¿¡æ¯ ===")
            for idx, record in enumerate(result['history'], 1):
                print(f"\nè®°å½• {idx}:")
                print(f"  æ—¥æœŸ: {record.get('date', 'N/A')}")
                print(f"  é…é€è®°å½•: {record.get('shipping_track_record', 'N/A')}")
                print(f"  è¯¦æƒ…: {record.get('details', 'N/A')}")
                print(f"  åŠå…¬å®¤: {record.get('office', 'N/A')}")
                print(f"  é‚®ç¼–: {record.get('zip_code', 'N/A')}")
                print(f"  éƒ½é“åºœå¿: {record.get('prefecture', 'N/A')}")
            
            # ä¿å­˜JSONæ ¼å¼æ•°æ®ï¼ˆåªä¿å­˜ historyï¼‰
            json_filepath = r"C:\Users\Administrator\Desktop\æµ·å¤–ä»“\è¿”å›å€¼.json"
            crawler.save_to_file(result, json_filepath, format='json')
            
            # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆåªä¿å­˜ historyï¼‰
            if crawler.db_manager:
                crawler.save_to_database(tracking_number, result)
                
                # æ£€æŸ¥æœ€åä¸€æ¡è®°å½•çš„çŠ¶æ€å¹¶æ›´æ–° Post_searchs.states
                if result['history']:
                    last_record = result['history'][-1]
                    shipping_record = str(last_record.get('shipping_track_record', ''))

                    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ç»ˆé…é€çŠ¶æ€
                    if 'Final delivery' in shipping_record:
                        crawler.db_manager.update_search_state(tracking_number, 'Final delivery')
                    else:
                        # å…¶ä»–æƒ…å†µå¦‚å®å†™å…¥è¯¥å€¼
                        crawler.db_manager.update_search_state(tracking_number, shipping_record)
            
            print("\n" + "=" * 50)
            print("æŸ¥è¯¢å®Œæˆï¼")
        else:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {tracking_number}ï¼Œè¯·æ£€æŸ¥è¿½è¸ªå·æˆ–ç½‘ç»œã€‚")
            failed_tracking_numbers.append(tracking_number)

    # å¦‚æœæœ‰æŸ¥è¯¢å¤±è´¥çš„å•å·ï¼Œè¿›è¡Œé‡è¯•
    if failed_tracking_numbers:
        print(f"\nğŸ”„ å‘ç° {len(failed_tracking_numbers)} ä¸ªæŸ¥è¯¢å¤±è´¥çš„å•å·ï¼Œå¼€å§‹é‡è¯•...")
        print("=" * 60)

        for tracking_number in failed_tracking_numbers:
            print(f"\nğŸ”„ é‡æ–°æŸ¥è¯¢å¤±è´¥å•å·: {tracking_number}")
            print("-" * 50)

            # é‡æ–°è·å–åŸå§‹HTMLå¹¶ä¿å­˜
            raw_html = crawler.fetch_raw_html(tracking_number)
            if raw_html:
                crawler.save_raw_html(raw_html, return_filepath)
                print(f"åŸå§‹HTMLå·²ä¿å­˜åˆ°: {return_filepath}")

                # æ£€æŸ¥æ˜¯å¦ä¸ºæœªæ³¨å†Œçš„å•å·
                if 'Your item was not found' in raw_html:
                    print("âŒ å‘ç°é”™è¯¯ï¼šå•å·æœªæ‰¾åˆ°")
                    if crawler.db_manager:
                        crawler.db_manager.update_search_state(tracking_number, 'Not registered')
                    print("\n" + "=" * 50)
                    print("âœ… é‡è¯•æŸ¥è¯¢æˆåŠŸï¼")
                    continue

            # é‡æ–°è·å–å¹¶è§£æè¿½è¸ªä¿¡æ¯
            result = crawler.fetch_tracking_info(tracking_number)

            if result:
                # æ‰“å°ç»“æœ
                print("\n=== å†å²ä¿¡æ¯ ===")
                for idx, record in enumerate(result['history'], 1):
                    print(f"\nè®°å½• {idx}:")
                    print(f"  æ—¥æœŸ: {record.get('date', 'N/A')}")
                    print(f"  é…é€è®°å½•: {record.get('shipping_track_record', 'N/A')}")
                    print(f"  è¯¦æƒ…: {record.get('details', 'N/A')}")
                    print(f"  åŠå…¬å®¤: {record.get('office', 'N/A')}")
                    print(f"  é‚®ç¼–: {record.get('zip_code', 'N/A')}")
                    print(f"  éƒ½é“åºœå¿: {record.get('prefecture', 'N/A')}")

                # ä¿å­˜JSONæ ¼å¼æ•°æ®ï¼ˆåªä¿å­˜ historyï¼‰
                json_filepath = r"C:\Users\Administrator\Desktop\æµ·å¤–ä»“\è¿”å›å€¼.json"
                crawler.save_to_file(result, json_filepath, format='json')

                # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆåªä¿å­˜ historyï¼‰
                if crawler.db_manager:
                    crawler.save_to_database(tracking_number, result)

                    # æ£€æŸ¥æœ€åä¸€æ¡è®°å½•çš„çŠ¶æ€å¹¶æ›´æ–° Post_searchs.states
                    if result['history']:
                        last_record = result['history'][-1]
                        shipping_record = str(last_record.get('shipping_track_record', ''))

                        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ç»ˆé…é€çŠ¶æ€
                        if 'Final delivery' in shipping_record:
                            crawler.db_manager.update_search_state(tracking_number, 'Final delivery')
                        else:
                            # å…¶ä»–æƒ…å†µå¦‚å®å†™å…¥è¯¥å€¼
                            crawler.db_manager.update_search_state(tracking_number, shipping_record)

                print("\n" + "=" * 50)
                print("âœ… é‡è¯•æŸ¥è¯¢æˆåŠŸï¼")
            else:
                print(f"âŒ é‡è¯•åä»æŸ¥è¯¢å¤±è´¥: {tracking_number}")

        print(f"\nğŸ“Š é‡è¯•å®Œæˆï¼Œå…±å¤„ç† {len(failed_tracking_numbers)} ä¸ªå¤±è´¥å•å·")

    # å…³é—­æ•°æ®åº“è¿æ¥
    crawler.close_database()


if __name__ == "__main__":
    main()

