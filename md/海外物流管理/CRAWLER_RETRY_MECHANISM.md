# 爬虫重试机制说明

## 📋 功能说明

爬虫现在支持自动重试机制：**失败的单号会自动重试，直到成功为止**（最多重试 50 次）。

## 🔄 重试逻辑

### 重试策略

1. **最大重试次数**：每个失败的单号最多重试 **50 次**（基本可以覆盖大部分临时故障）
2. **指数退避延迟**：重试之间的延迟时间逐渐增加
   - 第 1 次重试：等待 1 秒
   - 第 2 次重试：等待 2 秒
   - 第 3 次重试：等待 4 秒
   - 第 4 次重试：等待 8 秒
   - 第 5 次及以后：最多等待 10 秒
3. **重试条件**：
   - 网络错误
   - 解析错误
   - 返回 `null` 的情况（非 "Not registered"）

### 处理流程

```
开始处理追踪号
    ↓
尝试爬取追踪信息
    ↓
成功？
    ↓ (是)
保存数据并更新状态
    ↓
标记为成功
    ↓
结束

    ↓ (否)
重试次数 < 10？
    ↓ (是)
等待延迟时间（指数退避）
    ↓
重新尝试爬取
    ↓
回到"成功？"判断

    ↓ (否，达到最大重试次数 50 次)
标记为失败
    ↓
结束
```

## 📊 统计信息

重试机制会统计以下信息：

- **total**：总追踪号数量
- **success**：成功处理的追踪号数量（包括重试后成功的）
- **failed**：最终失败的追踪号数量（重试 10 次后仍失败）
- **skipped**：跳过的追踪号数量（已完成状态）
- **retries**：总重试次数

## 💡 代码实现

### 核心函数：`processTrackingNumber`

```typescript
async function processTrackingNumber(
  trackingNumber: string,
  maxRetries: number = 10
): Promise<{ success: boolean; retries: number }>
```

**功能**：
- 处理单个追踪号
- 自动重试失败的请求
- 返回处理结果和重试次数

**参数**：
- `trackingNumber`：要处理的追踪号
- `maxRetries`：最大重试次数（默认 50 次）

**返回值**：
- `success`：是否成功处理
- `retries`：实际重试次数

### 指数退避算法

```typescript
const delay = Math.min(1000 * Math.pow(2, retries - 1), 10000)
```

**说明**：
- 延迟时间 = `1000ms × 2^(retries-1)`
- 最多等待 10 秒（10000ms）
- 避免过于频繁的重试请求

## 📝 日志输出

重试过程中会输出详细的日志：

```
📋 开始处理 10 个追踪号...
============================================================

正在处理追踪号：628327933074
--------------------------------------------------
⚠️ 追踪号 628327933074 处理失败，准备重试 (1/50)...
✅ 成功处理追踪号：628327933074 (重试 1 次)

正在处理追踪号：628327933075
--------------------------------------------------
⚠️ 追踪号 628327933075 处理失败，准备重试 (1/50)...
⚠️ 追踪号 628327933075 处理失败，准备重试 (2/50)...
✅ 成功处理追踪号：628327933075 (重试 2 次)

============================================================
📊 爬虫执行完成
```

## ✅ 成功判断标准

以下情况会被视为**成功**：

1. ✅ **正常获取追踪信息**：成功解析 HTML 并提取历史记录
2. ✅ **识别为 "Not registered"**：成功识别未注册单号并更新状态
3. ✅ **重试后成功**：经过重试后成功处理

以下情况会被视为**失败**：

1. ❌ **达到最大重试次数**：重试 50 次后仍失败
2. ❌ **持续的网络错误**：无法连接到服务器
3. ❌ **持续的解析错误**：HTML 结构变化导致无法解析

## 🎯 使用场景

### 场景 1：网络临时故障

```
第 1 次尝试：网络超时 ❌
等待 1 秒
第 2 次尝试：成功 ✅
```

### 场景 2：服务器临时不可用

```
第 1 次尝试：HTTP 500 错误 ❌
等待 1 秒
第 2 次尝试：HTTP 500 错误 ❌
等待 2 秒
第 3 次尝试：成功 ✅
```

### 场景 3：持续失败

```
第 1-10 次尝试：全部失败 ❌
最终标记为失败
```

## ⚙️ 配置选项

可以在 `processTrackingNumber` 函数中调整：

- **最大重试次数**：修改 `maxRetries` 参数（默认 50 次）
- **延迟时间**：修改指数退避算法中的系数
- **最大延迟**：修改 `Math.min(..., 10000)` 中的 10000

## 📈 性能影响

### 优点

- ✅ 提高成功率：临时故障可以自动恢复
- ✅ 减少手动干预：无需人工重试失败的单号
- ✅ 更好的容错性：网络波动不会导致数据丢失

### 注意事项

- ⚠️ **执行时间增加**：重试会增加总执行时间
- ⚠️ **服务器压力**：频繁重试可能增加服务器压力
- ⚠️ **资源消耗**：重试会消耗更多网络和计算资源

## 🔍 监控建议

建议监控以下指标：

1. **重试率**：`retries / total` - 重试次数占总数的比例
2. **最终失败率**：`failed / total` - 最终失败的追踪号比例
3. **平均重试次数**：`retries / (success + failed)` - 每个追踪号平均重试次数

---

**更新日期**：2025-01-XX  
**相关文件**：
- `lib/logistics-crawler.ts`
- `CRAWLER_NOT_FOUND_HANDLING.md`

